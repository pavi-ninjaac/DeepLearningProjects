{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import cv2\n",
    "import hand_detector as hd"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "Error",
     "evalue": "Session cannot generate requests",
     "traceback": [
      "Error: Session cannot generate requests",
      "at w.executeCodeCell (/home/pavithra/.vscode/extensions/ms-toolsai.jupyter-2021.8.1054968649/out/client/extension.js:90:320068)",
      "at w.execute (/home/pavithra/.vscode/extensions/ms-toolsai.jupyter-2021.8.1054968649/out/client/extension.js:90:319389)",
      "at w.start (/home/pavithra/.vscode/extensions/ms-toolsai.jupyter-2021.8.1054968649/out/client/extension.js:90:315205)",
      "at processTicksAndRejections (internal/process/task_queues.js:93:5)",
      "at async t.CellExecutionQueue.executeQueuedCells (/home/pavithra/.vscode/extensions/ms-toolsai.jupyter-2021.8.1054968649/out/client/extension.js:90:329732)",
      "at async t.CellExecutionQueue.start (/home/pavithra/.vscode/extensions/ms-toolsai.jupyter-2021.8.1054968649/out/client/extension.js:90:329272)"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#get the basic info\n",
    "folder_name = ['rock', 'paper', 'scissors']\n",
    "folder_number = int(input(\"Enter the folder number/image class number 0)rock 1)paper 2)scissors\"))\n",
    "num_images = int(input(\"Enter the number of images needed for each class\"))\n",
    "\n",
    "#we need only right hand to playing\n",
    "hand_detector = hd.hand_detector(max_hands=1)\n",
    "\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "folder_path = \"/home/pavithra/learning/projects/rock-paper-seacer/dataset/{folder_name}/\".format(folder_name=folder_name[folder_number])\n",
    "img_count = 1\n",
    "while 1:\n",
    "    ret, img = video_capture.read()\n",
    "\n",
    "    # Draw the hand landmark.\n",
    "    img = hand_detector.detect_hand(img, draw_points=False)\n",
    "    # Get the 20 landmark points as a array.\n",
    "    hand_array = hand_detector.get_landmark_array(img,draw_tip=True)\n",
    "    if len(hand_array) != 0:\n",
    "        #get the cropeed hand image.\n",
    "        hand_img = hand_detector.draw_rectangle_hand(img, hand_array,crop_hand=True)\n",
    "        img_path = folder_path + folder_name[folder_number] + '_' + str(img_count) + '.jpg'\n",
    "        # print(img_path)\n",
    "        cv2.imwrite(img_path, hand_img)\n",
    "        img_count += 1\n",
    "    cv2.imshow(\"Live screen\", img)\n",
    "    \n",
    "\n",
    "    if (img_count == num_images) or (cv2.waitKey(1) & 0xFF == ord('q')):\n",
    "        break\n",
    "\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "Error",
     "evalue": "Session cannot generate requests",
     "traceback": [
      "Error: Session cannot generate requests",
      "at w.executeCodeCell (/home/pavithra/.vscode/extensions/ms-toolsai.jupyter-2021.8.1054968649/out/client/extension.js:90:320068)",
      "at w.execute (/home/pavithra/.vscode/extensions/ms-toolsai.jupyter-2021.8.1054968649/out/client/extension.js:90:319389)",
      "at w.start (/home/pavithra/.vscode/extensions/ms-toolsai.jupyter-2021.8.1054968649/out/client/extension.js:90:315205)",
      "at processTicksAndRejections (internal/process/task_queues.js:93:5)",
      "at async t.CellExecutionQueue.executeQueuedCells (/home/pavithra/.vscode/extensions/ms-toolsai.jupyter-2021.8.1054968649/out/client/extension.js:90:329732)",
      "at async t.CellExecutionQueue.start (/home/pavithra/.vscode/extensions/ms-toolsai.jupyter-2021.8.1054968649/out/client/extension.js:90:329272)"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "#Open Camera object\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "#Decrease frame size\n",
    "#cap.set(cv2.cv.CV_CAP_PROP_FRAME_WIDTH, 1000)\n",
    "#cap.set(cv2.cv.CV_CAP_PROP_FRAME_HEIGHT, 600)\n",
    "\n",
    "def nothing(x):\n",
    "    pass\n",
    "\n",
    "# Function to find angle between two vectors\n",
    "def Angle(v1,v2):\n",
    " dot = np.dot(v1,v2)\n",
    " x_modulus = np.sqrt((v1*v1).sum())\n",
    " y_modulus = np.sqrt((v2*v2).sum())\n",
    " cos_angle = dot / x_modulus / y_modulus\n",
    " angle = np.degrees(np.arccos(cos_angle))\n",
    " return angle\n",
    "\n",
    "# Function to find distance between two points in a list of lists\n",
    "def FindDistance(A,B): \n",
    " return np.sqrt(np.power((A[0][0]-B[0][0]),2) + np.power((A[0][1]-B[0][1]),2)) \n",
    " \n",
    "\n",
    "# Creating a window for HSV track bars\n",
    "cv2.namedWindow('HSV_TrackBar')\n",
    "\n",
    "# Starting with 100's to prevent error while masking\n",
    "h,s,v = 100,100,100\n",
    "\n",
    "# Creating track bar\n",
    "cv2.createTrackbar('h', 'HSV_TrackBar',0,179,nothing)\n",
    "cv2.createTrackbar('s', 'HSV_TrackBar',0,255,nothing)\n",
    "cv2.createTrackbar('v', 'HSV_TrackBar',0,255,nothing)\n",
    "\n",
    "while(1):\n",
    "\n",
    "    #Measure execution time \n",
    "    start_time = time.time()\n",
    "    \n",
    "    #Capture frames from the camera\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    #Blur the image\n",
    "    blur = cv2.blur(frame,(3,3))\n",
    " \t\n",
    " \t#Convert to HSV color space\n",
    "    hsv = cv2.cvtColor(blur,cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    #Create a binary image with where white will be skin colors and rest is black\n",
    "    mask2 = cv2.inRange(hsv,np.array([2,50,50]),np.array([15,255,255]))\n",
    "    \n",
    "    #Kernel matrices for morphological transformation    \n",
    "    kernel_square = np.ones((11,11),np.uint8)\n",
    "    kernel_ellipse= cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(5,5))\n",
    "    \n",
    "    #Perform morphological transformations to filter out the background noise\n",
    "    #Dilation increase skin color area\n",
    "    #Erosion increase skin color area\n",
    "    dilation = cv2.dilate(mask2,kernel_ellipse,iterations = 1)\n",
    "    erosion = cv2.erode(dilation,kernel_square,iterations = 1)    \n",
    "    dilation2 = cv2.dilate(erosion,kernel_ellipse,iterations = 1)    \n",
    "    filtered = cv2.medianBlur(dilation2,5)\n",
    "    kernel_ellipse= cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(8,8))\n",
    "    dilation2 = cv2.dilate(filtered,kernel_ellipse,iterations = 1)\n",
    "    kernel_ellipse= cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(5,5))\n",
    "    dilation3 = cv2.dilate(filtered,kernel_ellipse,iterations = 1)\n",
    "    median = cv2.medianBlur(dilation2,5)\n",
    "    ret,thresh = cv2.threshold(median,127,255,0)\n",
    "    \n",
    "    #Find contours of the filtered frame\n",
    "    contours, hierarchy = cv2.findContours(thresh,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)   \n",
    "    \n",
    "    #Draw Contours\n",
    "    #cv2.drawContours(frame, cnt, -1, (122,122,0), 3)\n",
    "    #cv2.imshow('Dilation',median)\n",
    "    \n",
    "\t#Find Max contour area (Assume that hand is in the frame)\n",
    "    max_area=100\n",
    "    ci=0\t\n",
    "    for i in range(len(contours)):\n",
    "        cnt=contours[i]\n",
    "        area = cv2.contourArea(cnt)\n",
    "        if(area>max_area):\n",
    "            max_area=area\n",
    "            ci=i  \n",
    "            \n",
    "\t#Largest area contour \t\t\t  \n",
    "    cnts = contours[ci]\n",
    "\n",
    "    #Find convex hull\n",
    "    hull = cv2.convexHull(cnts)\n",
    "    \n",
    "    #Find convex defects\n",
    "    hull2 = cv2.convexHull(cnts,returnPoints = False)\n",
    "    defects = cv2.convexityDefects(cnts,hull2)\n",
    "    \n",
    "    #Get defect points and draw them in the original image\n",
    "    FarDefect = []\n",
    "    for i in range(defects.shape[0]):\n",
    "        s,e,f,d = defects[i,0]\n",
    "        start = tuple(cnts[s][0])\n",
    "        end = tuple(cnts[e][0])\n",
    "        far = tuple(cnts[f][0])\n",
    "        FarDefect.append(far)\n",
    "        cv2.line(frame,start,end,[0,255,0],1)\n",
    "        cv2.circle(frame,far,10,[100,255,255],3)\n",
    "    \n",
    "\t#Find moments of the largest contour\n",
    "    moments = cv2.moments(cnts)\n",
    "    \n",
    "    #Central mass of first order moments\n",
    "    if moments['m00']!=0:\n",
    "        cx = int(moments['m10']/moments['m00']) # cx = M10/M00\n",
    "        cy = int(moments['m01']/moments['m00']) # cy = M01/M00\n",
    "    centerMass=(cx,cy)    \n",
    "    \n",
    "    #Draw center mass\n",
    "    cv2.circle(frame,centerMass,7,[100,0,255],2)\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    cv2.putText(frame,'Center',tuple(centerMass),font,2,(255,255,255),2)     \n",
    "    \n",
    "    #Distance from each finger defect(finger webbing) to the center mass\n",
    "    distanceBetweenDefectsToCenter = []\n",
    "    for i in range(0,len(FarDefect)):\n",
    "        x =  np.array(FarDefect[i])\n",
    "        centerMass = np.array(centerMass)\n",
    "        distance = np.sqrt(np.power(x[0]-centerMass[0],2)+np.power(x[1]-centerMass[1],2))\n",
    "        distanceBetweenDefectsToCenter.append(distance)\n",
    "    \n",
    "    #Get an average of three shortest distances from finger webbing to center mass\n",
    "    sortedDefectsDistances = sorted(distanceBetweenDefectsToCenter)\n",
    "    AverageDefectDistance = np.mean(sortedDefectsDistances[0:2])\n",
    " \n",
    "    #Get fingertip points from contour hull\n",
    "    #If points are in proximity of 80 pixels, consider as a single point in the group\n",
    "    finger = []\n",
    "    for i in range(0,len(hull)-1):\n",
    "        if (np.absolute(hull[i][0][0] - hull[i+1][0][0]) > 80) or ( np.absolute(hull[i][0][1] - hull[i+1][0][1]) > 80):\n",
    "            if hull[i][0][1] <500 :\n",
    "                finger.append(hull[i][0])\n",
    "    \n",
    "    #The fingertip points are 5 hull points with largest y coordinates  \n",
    "    finger =  sorted(finger,key=lambda x: x[1])   \n",
    "    fingers = finger[0:5]\n",
    "    \n",
    "    #Calculate distance of each finger tip to the center mass\n",
    "    fingerDistance = []\n",
    "    for i in range(0,len(fingers)):\n",
    "        distance = np.sqrt(np.power(fingers[i][0]-centerMass[0],2)+np.power(fingers[i][1]-centerMass[0],2))\n",
    "        fingerDistance.append(distance)\n",
    "    \n",
    "    #Finger is pointed/raised if the distance of between fingertip to the center mass is larger\n",
    "    #than the distance of average finger webbing to center mass by 130 pixels\n",
    "    result = 0\n",
    "    for i in range(0,len(fingers)):\n",
    "        if fingerDistance[i] > AverageDefectDistance+130:\n",
    "            result = result +1\n",
    "    \n",
    "    #Print number of pointed fingers\n",
    "    cv2.putText(frame,str(result),(100,100),font,2,(255,255,255),2)\n",
    "    \n",
    "    #show height raised fingers\n",
    "    #cv2.putText(frame,'finger1',tuple(finger[0]),font,2,(255,255,255),2)\n",
    "    #cv2.putText(frame,'finger2',tuple(finger[1]),font,2,(255,255,255),2)\n",
    "    #cv2.putText(frame,'finger3',tuple(finger[2]),font,2,(255,255,255),2)\n",
    "    #cv2.putText(frame,'finger4',tuple(finger[3]),font,2,(255,255,255),2)\n",
    "    #cv2.putText(frame,'finger5',tuple(finger[4]),font,2,(255,255,255),2)\n",
    "    #cv2.putText(frame,'finger6',tuple(finger[5]),font,2,(255,255,255),2)\n",
    "    #cv2.putText(frame,'finger7',tuple(finger[6]),font,2,(255,255,255),2)\n",
    "    #cv2.putText(frame,'finger8',tuple(finger[7]),font,2,(255,255,255),2)\n",
    "        \n",
    "    #Print bounding rectangle\n",
    "    x,y,w,h = cv2.boundingRect(cnts)\n",
    "    img = cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "    \n",
    "    cv2.drawContours(frame,[hull],-1,(255,255,255),2)\n",
    "    \n",
    "    ##### Show final image ########\n",
    "    cv2.imshow('Dilation',frame)\n",
    "    ###############################\n",
    "    \n",
    "    #Print execution time\n",
    "    #print time.time()-start_time\n",
    "    \n",
    "    #close the output video by pressing 'ESC'\n",
    "    k = cv2.waitKey(5) & 0xFF\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[ WARN:0] global /tmp/pip-req-build-xw6jtoah/opencv/modules/videoio/src/cap_v4l.cpp (890) open VIDEOIO(V4L2:/dev/video0): can't open camera by index\n",
      "[ WARN:0] global /tmp/pip-req-build-xw6jtoah/opencv/modules/highgui/src/window.cpp (703) createTrackbar UI/Trackbar(h@HSV_TrackBar): Using 'value' pointer is unsafe and deprecated. Use NULL as value pointer. To fetch trackbar value setup callback.\n",
      "[ WARN:0] global /tmp/pip-req-build-xw6jtoah/opencv/modules/highgui/src/window.cpp (703) createTrackbar UI/Trackbar(s@HSV_TrackBar): Using 'value' pointer is unsafe and deprecated. Use NULL as value pointer. To fetch trackbar value setup callback.\n",
      "[ WARN:0] global /tmp/pip-req-build-xw6jtoah/opencv/modules/highgui/src/window.cpp (703) createTrackbar UI/Trackbar(v@HSV_TrackBar): Using 'value' pointer is unsafe and deprecated. Use NULL as value pointer. To fetch trackbar value setup callback.\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "error",
     "evalue": "OpenCV(4.5.3) /tmp/pip-req-build-xw6jtoah/opencv/modules/imgproc/src/box_filter.dispatch.cpp:446: error: (-215:Assertion failed) !_src.empty() in function 'boxFilter'\n",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_37156/3739397828.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;31m#Blur the image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0mblur\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblur\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;31m#Convert to HSV color space\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.5.3) /tmp/pip-req-build-xw6jtoah/opencv/modules/imgproc/src/box_filter.dispatch.cpp:446: error: (-215:Assertion failed) !_src.empty() in function 'boxFilter'\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit"
  },
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}